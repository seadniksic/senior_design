{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 0. Install and Import Dependencies"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install tensorflow==2.4.1 tensorflow-gpu==2.4.1 tensorflow-hub opencv-python matplotlib"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2\n",
    "import tensorflow as tf\n",
    "import tensorflow_hub as hub\n",
    "\n",
    "from matplotlib import pyplot as plt\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Optional if you are using a GPU\n",
    "gpus = tf.config.experimental.list_physical_devices('GPU')\n",
    "for gpu in gpus:\n",
    "    tf.config.experimental.set_memory_growth(gpu, True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 1. Load Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-02-20 06:11:04.938160: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:984] could not open file to read NUMA node: /sys/bus/pci/devices/0000:00:00.0/numa_node\n",
      "Your kernel may have been built without NUMA support.\n",
      "2023-02-20 06:11:06.418056: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:984] could not open file to read NUMA node: /sys/bus/pci/devices/0000:00:00.0/numa_node\n",
      "Your kernel may have been built without NUMA support.\n",
      "2023-02-20 06:11:06.418668: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:984] could not open file to read NUMA node: /sys/bus/pci/devices/0000:00:00.0/numa_node\n",
      "Your kernel may have been built without NUMA support.\n",
      "2023-02-20 06:11:06.453127: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:984] could not open file to read NUMA node: /sys/bus/pci/devices/0000:00:00.0/numa_node\n",
      "Your kernel may have been built without NUMA support.\n",
      "2023-02-20 06:11:06.453691: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:984] could not open file to read NUMA node: /sys/bus/pci/devices/0000:00:00.0/numa_node\n",
      "Your kernel may have been built without NUMA support.\n",
      "2023-02-20 06:11:06.454125: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:984] could not open file to read NUMA node: /sys/bus/pci/devices/0000:00:00.0/numa_node\n",
      "Your kernel may have been built without NUMA support.\n",
      "2023-02-20 06:11:50.183480: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:984] could not open file to read NUMA node: /sys/bus/pci/devices/0000:00:00.0/numa_node\n",
      "Your kernel may have been built without NUMA support.\n",
      "2023-02-20 06:11:50.215442: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:984] could not open file to read NUMA node: /sys/bus/pci/devices/0000:00:00.0/numa_node\n",
      "Your kernel may have been built without NUMA support.\n",
      "2023-02-20 06:11:50.215716: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1703] Could not identify NUMA node of platform GPU id 0, defaulting to 0.  Your kernel may not have been built with NUMA support.\n",
      "2023-02-20 06:11:50.216242: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:984] could not open file to read NUMA node: /sys/bus/pci/devices/0000:00:00.0/numa_node\n",
      "Your kernel may have been built without NUMA support.\n",
      "2023-02-20 06:11:50.216580: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1616] Created device /job:localhost/replica:0/task:0/device:GPU:0 with 684 MB memory:  -> device: 0, name: Xavier, pci bus id: 0000:00:00.0, compute capability: 7.2\n"
     ]
    }
   ],
   "source": [
    "model = hub.load('https://tfhub.dev/google/movenet/multipose/lightning/1')\n",
    "movenet = model.signatures['serving_default']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 2. Make Detections"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "nvarguscamerasrc sensor-id=0 !video/x-raw(memory:NVMM), width=(int)1920, height=(int)1080, framerate=(fraction)30/1 ! nvvidconv flip-method=0 ! video/x-raw, width=(int)960, height=(int)540, format=(string)BGRx ! videoconvert ! video/x-raw, format=(string)BGR ! appsink\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "(python3:15297): GStreamer-WARNING **: 06:15:17.366: Failed to load plugin '/usr/lib/aarch64-linux-gnu/gstreamer-1.0/libgstnvarguscamerasrc.so': /lib/aarch64-linux-gnu/libGLdispatch.so.0: cannot allocate memory in static TLS block\n",
      "\n",
      "(python3:15297): GStreamer-WARNING **: 06:15:17.394: Failed to load plugin '/usr/lib/aarch64-linux-gnu/gstreamer-1.0/libgstnvvidconv.so': /lib/aarch64-linux-gnu/libGLdispatch.so.0: cannot allocate memory in static TLS block\n",
      "\n",
      "(python3:15297): GStreamer-CRITICAL **: 06:16:51.274: \n",
      "Trying to dispose element capsfilter0, but it is in PAUSED instead of the NULL state.\n",
      "You need to explicitly set elements to the NULL state before\n",
      "dropping the final reference, to allow them to clean up.\n",
      "This problem may also be caused by a refcounting bug in the\n",
      "application or some element.\n",
      "\n",
      "\n",
      "(python3:15297): GStreamer-CRITICAL **: 06:16:51.275: \n",
      "Trying to dispose element pipeline0, but it is in READY instead of the NULL state.\n",
      "You need to explicitly set elements to the NULL state before\n",
      "dropping the final reference, to allow them to clean up.\n",
      "This problem may also be caused by a refcounting bug in the\n",
      "application or some element.\n",
      "\n",
      "[ WARN:0] global /home/ubuntu/build_opencv/opencv/modules/videoio/src/cap_gstreamer.cpp (1053) open OpenCV | GStreamer warning: unable to start pipeline\n",
      "\n",
      "(python3:15297): GStreamer-CRITICAL **: 06:16:51.275: \n",
      "Trying to dispose element videoconvert0, but it is in PAUSED instead of the NULL state.\n",
      "You need to explicitly set elements to the NULL state before\n",
      "dropping the final reference, to allow them to clean up.\n",
      "This problem may also be caused by a refcounting bug in the\n",
      "application or some element.\n",
      "\n",
      "[ WARN:0] global /home/ubuntu/build_opencv/opencv/modules/videoio/src/cap_gstreamer.cpp (616) isPipelinePlaying OpenCV | GStreamer warning: GStreamer: pipeline have not been created\n",
      "\n",
      "(python3:15297): GStreamer-CRITICAL **: 06:16:51.275: \n",
      "Trying to dispose element appsink0, but it is in READY instead of the NULL state.\n",
      "You need to explicitly set elements to the NULL state before\n",
      "dropping the final reference, to allow them to clean up.\n",
      "This problem may also be caused by a refcounting bug in the\n",
      "application or some element.\n",
      "\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[7], line 33\u001b[0m\n\u001b[1;32m     31\u001b[0m \u001b[38;5;66;03m# To flip the image, modify the flip_method parameter (0 and 2 are the most common)\u001b[39;00m\n\u001b[1;32m     32\u001b[0m \u001b[38;5;28mprint\u001b[39m(gstreamer_pipeline(flip_method\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m0\u001b[39m))\n\u001b[0;32m---> 33\u001b[0m video_capture \u001b[38;5;241m=\u001b[39m \u001b[43mcv2\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mVideoCapture\u001b[49m\u001b[43m(\u001b[49m\u001b[43mgstreamer_pipeline\u001b[49m\u001b[43m(\u001b[49m\u001b[43mflip_method\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m0\u001b[39;49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcv2\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mCAP_GSTREAMER\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     34\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m video_capture\u001b[38;5;241m.\u001b[39misOpened():\n\u001b[1;32m     35\u001b[0m     \u001b[38;5;28;01mtry\u001b[39;00m:\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "def gstreamer_pipeline(\n",
    "    sensor_id=0,\n",
    "    capture_width=1920,\n",
    "    capture_height=1080,\n",
    "    display_width=960,\n",
    "    display_height=540,\n",
    "    framerate=30,\n",
    "    flip_method=0,\n",
    "):\n",
    "    return (\n",
    "        \"nvarguscamerasrc sensor-id=%d !\"\n",
    "        \"video/x-raw(memory:NVMM), width=(int)%d, height=(int)%d, framerate=(fraction)%d/1 ! \"\n",
    "        \"nvvidconv flip-method=%d ! \"\n",
    "        \"video/x-raw, width=(int)%d, height=(int)%d, format=(string)BGRx ! \"\n",
    "        \"videoconvert ! \"\n",
    "        \"video/x-raw, format=(string)BGR ! appsink\"\n",
    "        % (\n",
    "            sensor_id,\n",
    "            capture_width,\n",
    "            capture_height,\n",
    "            framerate,\n",
    "            flip_method,\n",
    "            display_width,\n",
    "            display_height,\n",
    "        )\n",
    "    )\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "# To flip the image, modify the flip_method parameter (0 and 2 are the most common)\n",
    "print(gstreamer_pipeline(flip_method=0))\n",
    "video_capture = cv2.VideoCapture(gstreamer_pipeline(flip_method=0), cv2.CAP_GSTREAMER)\n",
    "if video_capture.isOpened():\n",
    "    try:\n",
    "        window_handle = cv2.namedWindow(window_title, cv2.WINDOW_AUTOSIZE)\n",
    "        while True:\n",
    "            ret_val, frame = video_capture.read()\n",
    "            # Check to see if the user closed the window\n",
    "            # Under GTK+ (Jetson Default), WND_PROP_VISIBLE does not work correctly. Under Qt it does\n",
    "            # GTK - Substitute WND_PROP_AUTOSIZE to detect if window has been closed by user\n",
    "            \n",
    "            \n",
    "            # Resize image\n",
    "            img = frame.copy()\n",
    "            img = tf.image.resize_with_pad(tf.expand_dims(img, axis=0), 384,640)\n",
    "            input_img = tf.cast(img, dtype=tf.int32)\n",
    "            \n",
    "            # Detection section\n",
    "            results = movenet(input_img)\n",
    "            keypoints_with_scores = results['output_0'].numpy()[:,:,:51].reshape((6,17,3))\n",
    "    \n",
    "            # Render keypoints \n",
    "            loop_through_people(frame, keypoints_with_scores, EDGES, 0.1)\n",
    "    \n",
    "            #cv2.imshow('Movenet Multipose', frame)\n",
    "            \n",
    "            if cv2.getWindowProperty(window_title, cv2.WND_PROP_AUTOSIZE) >= 0:\n",
    "                cv2.imshow('Movenet Multipose', frame)\n",
    "            else:\n",
    "                break \n",
    "            keyCode = cv2.waitKey(10) & 0xFF\n",
    "            # Stop the program on the ESC key or 'q'\n",
    "            if keyCode == 27 or keyCode == ord('q'):\n",
    "                break\n",
    "    finally:\n",
    "        video_capture.release()\n",
    "        cv2.destroyAllWindows()\n",
    "else:\n",
    "    print(\"Error: Unable to open camera\")\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "# cap = cv2.VideoCapture('novak.mp4')\n",
    "# while cap.isOpened():\n",
    "#     ret, frame = cap.read()\n",
    "    \n",
    "#     # Resize image\n",
    "#     img = frame.copy()\n",
    "#     img = tf.image.resize_with_pad(tf.expand_dims(img, axis=0), 384,640)\n",
    "#     input_img = tf.cast(img, dtype=tf.int32)\n",
    "    \n",
    "#     # Detection section\n",
    "#     results = movenet(input_img)\n",
    "#     keypoints_with_scores = results['output_0'].numpy()[:,:,:51].reshape((6,17,3))\n",
    "    \n",
    "#     # Render keypoints \n",
    "#     loop_through_people(frame, keypoints_with_scores, EDGES, 0.1)\n",
    "    \n",
    "#     cv2.imshow('Movenet Multipose', frame)\n",
    "    \n",
    "#     if cv2.waitKey(10) & 0xFF==ord('q'):\n",
    "#         break\n",
    "# cap.release()\n",
    "# cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "keypoints_with_scores"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "384"
      ]
     },
     "execution_count": 77,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "32*12"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function to loop through each person detected and render\n",
    "def loop_through_people(frame, keypoints_with_scores, edges, confidence_threshold):\n",
    "    for person in keypoints_with_scores:\n",
    "        draw_connections(frame, person, edges, confidence_threshold)\n",
    "        draw_keypoints(frame, person, confidence_threshold)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 3. Draw Keypoints"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def draw_keypoints(frame, keypoints, confidence_threshold):\n",
    "    y, x, c = frame.shape\n",
    "    shaped = np.squeeze(np.multiply(keypoints, [y,x,1]))\n",
    "    \n",
    "    for kp in shaped:\n",
    "        ky, kx, kp_conf = kp\n",
    "        if kp_conf > confidence_threshold:\n",
    "            cv2.circle(frame, (int(kx), int(ky)), 6, (0,255,0), -1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 4. Draw Edges"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "EDGES = {\n",
    "    (0, 1): 'm',\n",
    "    (0, 2): 'c',\n",
    "    (1, 3): 'm',\n",
    "    (2, 4): 'c',\n",
    "    (0, 5): 'm',\n",
    "    (0, 6): 'c',\n",
    "    (5, 7): 'm',\n",
    "    (7, 9): 'm',\n",
    "    (6, 8): 'c',\n",
    "    (8, 10): 'c',\n",
    "    (5, 6): 'y',\n",
    "    (5, 11): 'm',\n",
    "    (6, 12): 'c',\n",
    "    (11, 12): 'y',\n",
    "    (11, 13): 'm',\n",
    "    (13, 15): 'm',\n",
    "    (12, 14): 'c',\n",
    "    (14, 16): 'c'\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def draw_connections(frame, keypoints, edges, confidence_threshold):\n",
    "    y, x, c = frame.shape\n",
    "    shaped = np.squeeze(np.multiply(keypoints, [y,x,1]))\n",
    "    \n",
    "    for edge, color in edges.items():\n",
    "        p1, p2 = edge\n",
    "        y1, x1, c1 = shaped[p1]\n",
    "        y2, x2, c2 = shaped[p2]\n",
    "        \n",
    "        if (c1 > confidence_threshold) & (c2 > confidence_threshold):      \n",
    "            cv2.line(frame, (int(x1), int(y1)), (int(x2), int(y2)), (0,0,255), 4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
